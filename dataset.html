<!DOCTYPE HTML>

<html>

<head>
  <title>MMVR</title>

  <link rel="stylesheet" href="template.css">
</head>

<body>
  <br>

  <center><span style="font-size: 44px; font-weight: bold;">Multi-modal Robustness Analysis Against Language and Visual Perturbations</span></center><br/>

  <table align=center width=600px>
    <tr>
      <td align=center width=150px>
        <center>
          <span style="font-size: 22px">
            <a href="." target="_top">[Home]</a>
          </span>
        </center>
      </td>
      
<!--       <td align=center width=150px>
        <center>
          <span style="font-size: 22px">
            <a href="." target="_top">[Paper]</a>
          </span>
        </center>
      </td> -->

      <td align=center width=150px>
        <center>
          <span style="font-size: 22px">
            <a href="./dataset.html" target="_top">[Dataset]</a>
          </span>
        </center>
      </td>
      
<!--       <td align=center width=150px>
        <center>
          <span style="font-size: 22px">
            <a href="./code/code.zip" target="_top">[Code]</a>
          </span>
        </center>
      </td> -->

      <td align=center width=150px>
        <center>
          <span style="font-size: 22px">
            <a href="./examples.html" target="_top">[Examples]</a>
          </span>
        </center>
      </td>
      
    </tr>
  </table>

  <br>
  <br>


<hr> <br>
    <h2>Datasets</h2>
  <b><a href="https://paperswithcode.com/dataset/msr-vtt">MSRVTT</a></b> dataset consists of 10,000 clips with an average length of 10 seconds each.  These videos show a variety of activities that can be organized into 20 categories.
  <b><a href="https://paperswithcode.com/dataset/youcook2">YouCook2</a></b> is a task-oriented cooking dataset with 2000 long untrimmed videos from 89 cooking recipes.
  Each video is annotated with captions with provided temporal boundaries, allowing each video to be split into a set of
  clips. There are 3,305 test clip-text pairs from 457 videos for evaluation.
  YouCook2 has no indication of gender with phrases comprising 2x more nouns compared to MSRVTT while MSRVTT has a more
  uniform distribution of words with an increased vocab size of 568 more unique words.  YouCook2 are long, complex activities
  split into clips with temporally bounded annotations.

    <h2>Text Perturbations</h2>
    <center>Perlexity Scores Using GPT-3</center>
    <table align=center width=800px>
      <center><img src="./images/PerplexityScores.png" width=800px /></center>
      The perplexity scores for the different text perturbations using GPT-3.
      The bars represent the average perplexity for the entire corpus, the dashed lines represent the perplexity when
      removing outliers based on a threshold of a 500, and the numbers atop the bars are the percent of outliers that
      are removed when using the threshold. In summary, machine-learning based approaches <b>are likely to struggle most with character swapping perturbations and shuffling of words</b>.
      <br>
      <br>
      <center><img src="./images/TextMetrics.png" width=600px /></center>
      We also compare the perturbed text to the original text using the traditional metrics, BLEU,
      METEOR and Rouge. The results for these are averaged across the different perturbations for each type for both the
      MSRVTT and YouCook2 datasets.
      In summary, these scores indicate that we have a varying level of difficulty with our text perturbations across
      categories, allowing for variable securities of distribution shift. The <b>most challenging is DropText</b> and
      <b>the least challenging is Bias</b>.
    </table>
  <h2>Visual Perturbations</h2>

  <table align=center width=800px>
    <center>
      <img src="./images/TemporalImageGrid.png" width=800 />
    </center>
    <center>Temporal Examples </center><br>
    <center>
      <img src="./images/ImageGrid.png" width=800px />

    </center>
    <center>Spatio(and Spatio-Temporal) Examples</center><br>

  </table>
  <br>
  <br>
  
</body>

</html>
